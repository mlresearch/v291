---
title: The title of the paper
section: Original Papers
abstract: " We study the problem of imitating an expert demonstrator in a discrete-time,
  continuous state-and-action space control system. We show that there exist  stable
  dynamics (i.e. contracting exponentially quickly) and smooth, deterministic experts
  such that any smooth, deterministic imitator policy  necessarily suffers  error
  on execution that is  exponentially larger, as a function of problem horizon, than
  \ the error under the distribution of expert training data. Our negative result
  applies to both behavior cloning and offline-RL algorithms, unless  they produce
  highly \\emph{improper} imitator policies — those which are non-smooth, non-Markovian,
  or which  exhibit highly state-dependent stochasticity — or unless the expert trajectory
  distribution is sufficiently spread. We provide preliminary evidence of the benefits
  of these more complex policy parameterizations, explicating the benefits of today’s
  popular policy parameterizations in robot learning (e.g. action-chunking and diffusion-policies).
  We also establish a host of complementary negative and positive results for imitation
  in control systems.  "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: simchowitz25a
month: 0
tex_title: The title of the paper
firstpage: 5248
lastpage: 5351
page: 5248-5351
order: 5248
cycles: false
bibtex_author: Simchowitz, Max and Pfrommer, Daniel and Jadbabaie, Ali
author:
- given: Max
  family: Simchowitz
- given: Daniel
  family: Pfrommer
- given: Ali
  family: Jadbabaie
date: 2025-07-02
address:
container-title: Proceedings of Thirty Eighth Conference on Learning Theory
volume: '291'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 2
pdf: https://raw.githubusercontent.com/mlresearch/v291/main/assets/simchowitz25a/simchowitz25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
