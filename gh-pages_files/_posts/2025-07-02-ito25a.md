---
title: Instance-Dependent Regret Bounds for Learning Two-Player Zero-Sum Games with
  Bandit Feedback
section: Original Papers
abstract: No-regret self-play learning dynamics have become one of the premier ways
  to solve large-scale games in practice. Accelerating their convergence via improving
  the regret of the players over the naive $O(\sqrt{T})$ bound after $T$ rounds has
  been extensively studied in recent years, but almost all studies assume access to
  exact gradient feedback. We address the question of whether acceleration is possible
  under bandit feedback only and provide an affirmative answer for two-player zero-sum
  normal-form games. Specifically, we show that if both players apply the Tsallis-INF
  algorithm of Zimmert and Seldin (2021), then their regret is at most $O(c_1 \log
  T +  \sqrt{c_2 T})$, where $c_1$ and $c_2$ are game-dependent constants that characterize
  the difficulty of learning  $c_1$ resembles the complexity of learning a stochastic
  multi-armed bandit instance and depends inversely on some gap measures, while $c_2$
  can be much smaller than the number of actions when the Nash equilibria have a small
  support or are close to the boundary. In particular, for the case when a pure strategy
  Nash equilibrium exists, $c_2$ becomes zero, leading to an optimal instance-dependent
  regret bound as we show. We additionally prove that in this case our algorithm also
  enjoys last-iterate convergence and can identify the pure strategy Nash equilibrium
  with near-optimal sample complexity.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ito25a
month: 0
tex_title: Instance-Dependent Regret Bounds for Learning Two-Player Zero-Sum Games
  with Bandit Feedback
firstpage: 2858
lastpage: 2892
page: 2858-2892
order: 2858
cycles: false
bibtex_author: Ito, Shinji and Luo, Haipeng and Tsuchiya, Taira and Wu, Yue
author:
- given: Shinji
  family: Ito
- given: Haipeng
  family: Luo
- given: Taira
  family: Tsuchiya
- given: Yue
  family: Wu
date: 2025-07-02
address:
container-title: Proceedings of Thirty Eighth Conference on Learning Theory
volume: '291'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 2
pdf: https://raw.githubusercontent.com/mlresearch/v291/main/assets/ito25a/ito25a.pdf
extras:
- label: Supplementary ZIP
  link: https://raw.githubusercontent.com/mlresearch/v291/main/assets/assets/ito25a/ito25a-supp.zip
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
