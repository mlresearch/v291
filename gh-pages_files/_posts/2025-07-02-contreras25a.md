---
title: Non-Euclidean High-Order Smooth Convex Optimization Extended Abstract
section: Original Papers
abstract: 'We develop algorithms for the optimization of convex objectives that have
  Hölder continuous $q$-th derivatives by using a $q$-th order oracle, for any $q
  \geq 1$. Our algorithms work for general norms under mild conditions, including
  the $\ell_p$-settings for $1\leq p\leq \infty$. We can also optimize structured
  functions that allow for inexactly implementing a non-Euclidean ball optimization
  oracle. We do this by developing a non-Euclidean inexact accelerated proximal point
  method that makes use of an \textit{inexact uniformly convex regularizer}.  We show
  a lower bound for general norms that demonstrates our algorithms are nearly optimal
  in high-dimensions in the black-box oracle model for $\ell_p$-settings and all $q
  \geq 1$, even in randomized and parallel settings. This new lower bound, when applied
  to the first-order smooth case, resolves an open question in parallel convex optimization. '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: contreras25a
month: 0
tex_title: Non-Euclidean High-Order Smooth Convex Optimization Extended Abstract
firstpage: 1330
lastpage: 1330
page: 1330-1330
order: 1330
cycles: false
bibtex_author: Contreras, Juan Pablo and Guzm\'an, Crist\'obal and Mart\'{\i}nez-Rubio,
  David
author:
- given: Juan Pablo
  family: Contreras
- given: Cristóbal
  family: Guzmán
- given: David
  family: Martı́nez-Rubio
date: 2025-07-02
address:
container-title: Proceedings of Thirty Eighth Conference on Learning Theory
volume: '291'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 2
pdf: https://raw.githubusercontent.com/mlresearch/v291/main/assets/contreras25a/contreras25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
