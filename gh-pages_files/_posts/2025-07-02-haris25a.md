---
title: Compression Barriers in Autoregressive Transformers
section: Original Papers
abstract: 'A key limitation of autoregressive Transformers is the large memory needed
  at inference-time to cache all previous key-value (KV) embeddings. Prior works address
  this by compressing the KV cache but often assume specific structural properties
  of the embeddings. This raises the following natural question: Can truly sublinear
  space utilization be achieved without such assumptions? In this work, we answer
  this question in the negative. Any algorithm for attention-based token generation
  must use $\Theta(nd)$ space, where $n$ is the number of tokens generated so far
  and $d \geq \Omega(\log n)$ is the dimension of the KV embeddings. Our proof involves
  a reduction from a classic communication complexity problem and uses a randomized
  construction that leverages properties of projections in the spirit of the Johnson-Linderstrauss
  lemma. For the low-dimensional regime $d = o(\log n)$, we show that any algorithm
  requires $\Omega(de^d)$ space and prove, using tight bounds on covering numbers,
  that \textsc{SubGen}, proposed by Zandieh, Han, Mirrokni, and Karbasi (2024), matches
  this bound.  Further, we investigate how sparsity assumptions enable token generation
  in truly sublinear space, presenting impossibility results and proposing a new KV
  cache compression algorithm for sliding window attention when the value cache outside
  the window is unmasked.  Finally, we analyze token generationâ€™s time complexity,
  using an indistinguishability argument to prove that no non-adaptive algorithm can
  compute attention online in sublinear time for all tokens. '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: haris25a
month: 0
tex_title: Compression Barriers in Autoregressive Transformers
firstpage: 2757
lastpage: 2785
page: 2757-2785
order: 2757
cycles: false
bibtex_author: Haris, Themistoklis and Onak, Krzysztof
author:
- given: Themistoklis
  family: Haris
- given: Krzysztof
  family: Onak
date: 2025-07-02
address:
container-title: Proceedings of Thirty Eighth Conference on Learning Theory
volume: '291'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 2
pdf: https://raw.githubusercontent.com/mlresearch/v291/main/assets/haris25a/haris25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
