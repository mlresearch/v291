---
title: Rate-Preserving Reductions for Blackwell Approachability
section: Original Papers
abstract: 'Abernethy et al. (2011) showed that Blackwell approachability and no-regret
  learning are equivalent, in the sense that any algorithm that solves a specific
  Blackwell approachability instance can be converted to a sublinear regret algorithm
  for a specific no-regret learning instance, and vice versa. In this paper, we study
  a more fine-grained form of such reductions, and ask when this translation between
  problems preserves not only a sublinear rate of convergence, but also preserves
  the optimal rate of convergence. That is, in which cases does it suffice to find
  the optimal regret bound for a no-regret learning instance in order to find the
  optimal rate of convergence for a corresponding approachability instance?  We show
  that the reduction of Abernethy et al. (2011) (and of other subsequent work) does
  not preserve rates: their reduction may reduce a $d$-dimensional approachability
  instance $\mathcal{I}_1$ with optimal convergence rate $R_1$ to a no-regret learning
  instance $\mathcal{I}_2$ with optimal regret-per-round of $R_2$, with $R_{2}/R_{1}$
  arbitrarily large (in particular, it is possible that $R_1 = 0$ and $R_{2} > 0$).
  On the other hand, we show that it is possible to tightly reduce any approachability
  instance to an instance of a generalized form of regret minimization we call \emph{improper
  $\phi$-regret minimization} (a variant of the $\phi$-regret minimization of Gordon
  et al. (2008) where the transformation functions may map actions outside of the
  action set).  Finally, we characterize when linear transformations suffice to reduce
  improper $\phi$-regret minimization problems to standard classes of regret minimization
  problems (such as external regret minimization and proper $\phi$-regret minimization)
  in a rate preserving manner. We prove that some improper $\phi$-regret minimization
  instances cannot be reduced to either subclass of instance in this way, suggesting
  that approachability can capture some problems that cannot be easily phrased in
  the standard language of online learning.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dann25a
month: 0
tex_title: Rate-Preserving Reductions for Blackwell Approachability
firstpage: 1380
lastpage: 1414
page: 1380-1414
order: 1380
cycles: false
bibtex_author: Dann, Christoph and Mansour, Yishay and Mohri, Mehryar and Schneider,
  Jon and Sivan, Balasubramanian
author:
- given: Christoph
  family: Dann
- given: Yishay
  family: Mansour
- given: Mehryar
  family: Mohri
- given: Jon
  family: Schneider
- given: Balasubramanian
  family: Sivan
date: 2025-07-02
address:
container-title: Proceedings of Thirty Eighth Conference on Learning Theory
volume: '291'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 2
pdf: https://raw.githubusercontent.com/mlresearch/v291/main/assets/dann25a/dann25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
