---
title: On the Minimax Regret of Sequential Probability Assignment via Square-Root
  Entropy
section: Original Papers
abstract: 'We study the problem of sequential probability assignment under  logarithmic
  loss, both with and without side information. Our objective is to analyze the \emph{minimax
  regret}—a notion extensively studied in the literature—in terms of geometric quantities,
  such as covering numbers and scale-sensitive dimensions.  We show that the minimax
  regret for the case of no side information (equivalently, the Shtarkov sum) can
  be upper bounded in terms of \emph{sequential square-root entropy}, a  notion closely
  related to Hellinger distance. For the problem of sequential probability assignment
  with side information, we develop both upper and lower bounds based on the aforementioned
  entropy. The lower bound matches the upper bound, up to log factors, for classes
  in the Donsker regime (according to our definition of entropy). '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jia25a
month: 0
tex_title: On the Minimax Regret of Sequential Probability Assignment via Square-Root
  Entropy
firstpage: 2958
lastpage: 3016
page: 2958-3016
order: 2958
cycles: false
bibtex_author: Jia, Zeyu and Rakhlin, Alexander and Polyanskiy, Yury
author:
- given: Zeyu
  family: Jia
- given: Alexander
  family: Rakhlin
- given: Yury
  family: Polyanskiy
date: 2025-07-02
address:
container-title: Proceedings of Thirty Eighth Conference on Learning Theory
volume: '291'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 2
pdf: https://raw.githubusercontent.com/mlresearch/v291/main/assets/jia25a/jia25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
