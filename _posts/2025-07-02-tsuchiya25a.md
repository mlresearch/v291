---
title: Corrupted Learning Dynamics in Games
section: Original Papers
abstract: Learning in games refers to scenarios where multiple players interact in
  a shared environment, each aiming to minimize their regret. It is well known that
  an equilibrium can be computed at a fast rate of $O(1/T)$ when all players follow
  the optimistic follow-the-regularized-leader (OFTRL). However, this acceleration
  is limited to the \textit{honest regime}, in which all players fully adhere to a
  prescribed algorithmâ€”a situation that may not be realistic in practice. To address
  this issue, we present \textit{corrupted learning dynamics} that adaptively find
  an equilibrium at a rate that depends on the extent to which each player deviates
  from the strategy suggested by the prescribed algorithm. First, in two-player zero-sum
  corrupted games, we provide learning dynamics for which the external regret of the
  $x$-player (and similarly for the $y$-player) is roughly bounded by $O(\log (m_x
  m_y) + \sqrt{\hat{C}_y} + \hat{C}_x)$, where $m_x$ and $m_y$ denote the number of
  actions of the $x$- and $y$-players, respectively, and $\hat{C}_x$ and $\hat{C}_y$
  represent their cumulative deviations. We then extend our approach to multiplayer
  general-sum corrupted games, providing learning dynamics for which the swap regret
  of player $i$ is bounded by $O(\log T + \sqrt{\sum_{k} \hat{C}_k \log T} + \hat{C}_i)$
  ignoring dependence on the number of players and actions, where $\hat{C}_i$ is the
  cumulative deviation of player $i$ from the prescribed algorithm. Our learning dynamics
  are agnostic to the levels of corruption. A key technical contribution is a new
  analysis that ensures the stability of a stationary distribution of a Markov chain
  under a new adaptive learning rate, thereby allowing us to achieve the desired bound
  in the corrupted regime while matching the best existing bound in the honest regime.
  Notably, our framework can be extended to address not only corruption in strategies
  but also corruption in the observed expected utilities, and we provide several matching
  lower bounds.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tsuchiya25a
month: 0
tex_title: Corrupted Learning Dynamics in Games
firstpage: 5506
lastpage: 5552
page: 5506-5552
order: 5506
cycles: false
bibtex_author: Tsuchiya, Taira and Ito, Shinji and Luo, Haipeng
author:
- given: Taira
  family: Tsuchiya
- given: Shinji
  family: Ito
- given: Haipeng
  family: Luo
date: 2025-07-02
address:
container-title: Proceedings of Thirty Eighth Conference on Learning Theory
volume: '291'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 2
pdf: https://raw.githubusercontent.com/mlresearch/v291/main/assets/tsuchiya25a/tsuchiya25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
