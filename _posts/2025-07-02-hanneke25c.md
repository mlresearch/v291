---
title: Universal Rates for Multiclass Learning with Bandit Feedback
section: Original Papers
abstract: The seminal work of (Daniely et al., COLT 2011) introduced the problem of
  multiclass learning under bandit feedback and provided a combinatorial characterization
  of its learnability within the framework of PAC learning. In multiclass learning
  under bandit feedback, there is an unknown data distribution over an instance space
  $\mathcal{X}$ and a label space $\mathcal{Y}$ similar to classical multiclass learning,
  but the learner does not directly observe the correct labels of the i.i.d. training
  examples. Instead, during each round, the learner receives an example, makes a prediction
  for its label, and receives bandit feedback only indicating whether the prediction
  is correct. Despite this restriction, the goal remains the same as in classical
  multiclass learning. In the present work, we study the problem of multiclass learning
  under bandit feedback within the framework of \emph{universal learning} (Bousquet
  et al., STOC 2021). This makes it possible to study the behavior of learning curves.
  In the \emph{uniform learning} framework, no concept class $\mathcal{C}$ is learnable
  when the effective label space is unbounded. In contrast, surprisingly, we demonstrate
  that the universal learnability of concept classes $\mathcal{C}$ even when the effective
  label space is unbounded gives rise to a rich theory. More concretely, our primary
  contribution is a theory that reveals an inherent trichotomy governing instance
  optimal learning curves in the realizable setting. Moreover, the best achievable
  universal learning rate for any given concept class can only decay either at an
  \emph{exponential}, a \emph{linear}, or an \emph{arbitrarily slow} rate. In particular,
  the trichotomy is combinatorially characterized by the absence of an infinite multiclass
  Littlestone tree and the combination of an infinite Natarajan Littlestone tree and
  an infinite progressive Littlestone tree. Furthermore, we introduce novel learning
  algorithms for achieving instance optimal universal rates.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hanneke25c
month: 0
tex_title: Universal Rates for Multiclass Learning with Bandit Feedback
firstpage: 2704
lastpage: 2756
page: 2704-2756
order: 2704
cycles: false
bibtex_author: Hanneke, Steve and Shaeiri, Amirreza and Zhang, Qian
author:
- given: Steve
  family: Hanneke
- given: Amirreza
  family: Shaeiri
- given: Qian
  family: Zhang
date: 2025-07-02
address:
container-title: Proceedings of Thirty Eighth Conference on Learning Theory
volume: '291'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 2
pdf: https://raw.githubusercontent.com/mlresearch/v291/main/assets/hanneke25c/hanneke25c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
