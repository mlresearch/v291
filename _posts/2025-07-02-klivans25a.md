---
title: Learning Constant-Depth Circuits in Malicious Noise Models
section: Original Papers
abstract: 'The seminal work of Linial, Mansour, and Nisan gave a quasipolynomial-time
  algorithm for learning constant-depth circuits ($\mathsf{AC}^0$) with respect to
  the uniform distribution on the hypercube.  Extending their algorithm to the setting
  of malicious noise, where both covariates and labels can be adversarially corrupted,
  has remained open.  Here we achieve such a result, inspired by recent work on learning
  with distribution shift. Our running time essentially matches their algorithm, which
  is known to be optimal assuming various cryptographic primitives. Our proof uses
  a simple outlier-removal method combined with Braverman’s theorem for fooling constant-depth
  circuits.  We attain the best possible dependence on the noise rate and succeed
  in the harshest possible noise model (i.e., contamination or so-called “nasty noise"). '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: klivans25a
month: 0
tex_title: Learning Constant-Depth Circuits in Malicious Noise Models
firstpage: 3253
lastpage: 3263
page: 3253-3263
order: 3253
cycles: false
bibtex_author: Klivans, Adam and Stavropoulos, Konstantinos and Vasilyan, Arsen
author:
- given: Adam
  family: Klivans
- given: Konstantinos
  family: Stavropoulos
- given: Arsen
  family: Vasilyan
date: 2025-07-02
address:
container-title: Proceedings of Thirty Eighth Conference on Learning Theory
volume: '291'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 2
pdf: https://raw.githubusercontent.com/mlresearch/v291/main/assets/klivans25a/klivans25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
