---
title: A Fine-grained Characterization of PAC Learnability
section: Original Papers
abstract: 'In the multiclass PAC setting, even when full learnability is unattainable,
  meaningful information can often be extracted to guide predictions. However, classical
  learning theory has mainly focused on the dichotomy “learnable vs. non-learnable”,
  leaving notions of partial learnability largely unexplored. Indeed, even for a non-learnable
  class, a learner may still achieve partial success-for example, by making reliable
  predictions whenever the true label belongs to a fixed subset of the label space,
  even if it fails otherwise. Similarly, the rigid nature of PAC learnability makes
  it impossible to distinguish between classes where one can achieve favorable trade-offs
  between, say, false-positive and false-negative rates, and classes where such trade-offs
  are fundamentally unattainable.  In a nutshell, standard PAC learnability precludes
  a fine-grained exploration of learnability. To overcome this limitation, we develop
  a fine-grained theory of PAC learnability. For any hypothesis class $\mathcal{H}$,
  given a loss function (which quantifies the penalty for predicting $\hat{y}$ instead
  of the true label $y$) and a target loss threshold $z$, our theory determines whether
  it is possible to achieve a loss of at most $z$. In contrast, classical PAC learning
  considers only the special case of the zero-one loss and $z = 0$, corresponding
  to a near perfect classification guarantee. We give a complete characterization
  of all attainable guarantees, captured by a \emph{finite family} of combinatorial
  dimensions, which we term the \emph{$J$-cube dimensions} of $\mathcal{H}$. These
  dimensions are defined for every subset $J$ of at least two labels. This extends
  the fundamental theorem of realizable PAC learning based on the VC dimension. In
  fact, our results hold in a more general multi-objective setting where we fully
  characterize the Pareto frontier of guarantees attainable for the class $\mathcal{H}$. '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bressan25b
month: 0
tex_title: A Fine-grained Characterization of PAC Learnability
firstpage: 641
lastpage: 676
page: 641-676
order: 641
cycles: false
bibtex_author: Bressan, Marco and Brukhim, Nataly and Cesa-Bianchi, Nicol{\`o} and
  Esposito, Emmanuel and Mansour, Yishay and Moran, Shay and Thiessen, Maximilian
author:
- given: Marco
  family: Bressan
- given: Nataly
  family: Brukhim
- given: Nicolò
  family: Cesa-Bianchi
- given: Emmanuel
  family: Esposito
- given: Yishay
  family: Mansour
- given: Shay
  family: Moran
- given: Maximilian
  family: Thiessen
date: 2025-07-02
address:
container-title: Proceedings of Thirty Eighth Conference on Learning Theory
volume: '291'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 2
pdf: https://raw.githubusercontent.com/mlresearch/v291/main/assets/bressan25b/bressan25b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
